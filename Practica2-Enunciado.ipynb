{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "<img style=\"float:left\" width=\"40%\" src=\"pics/escudo_COLOR_1L_DCHA.png\">\n",
    "<img style=\"float:right\" width=\"12%\" src=\"pics/PythonLogo.svg\">\n",
    "<br style=\"clear:both;\">\n",
    "\n",
    "# Sistemas Inteligentes aplicados en Salud\n",
    "\n",
    "<h2 style=\"display: inline-block; padding: 4mm; padding-left: 2em; background-color: navy; line-height: 1.3em; color: white; border-radius: 10px;\">Práctica 2: Reconocimiento de formas con redes neuronales</h2>\n",
    "<br style=\"clear:both;\">\n",
    "<h2 style=\"display: inline-block; padding: 4mm; padding-left: 2em; background-color: orange; line-height: 1.3em; color: white; border-radius: 10px;\">Enunciado y tareas</h2>\n",
    "\n",
    "### Grado en Ingeniería de la Salud \n",
    "\n",
    "  **Curso 24-25**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reconocimiento de formas\n",
    "\n",
    "En esta práctica se va a trabajar con el *reconocimiento de formas* (*pattern recognition*, en inglés).\n",
    "\n",
    "Las imágenes con las que se va a trabajar pertenecen a la familia de imágenes **MNIST**, cuya versión original se puede obtener en http://yann.lecun.com/exdb/mnist/(URL verificada en octubre del 2024). \n",
    "\n",
    "MNIST significa *Modified NIST*, donde, a su vez, NIST quiere decir *National Institute of Standards and Technology*. La palabra clave es **modified**. MNIST se constituye de una serie de imágenes de dígitos escritos a mano alzada, entre 0 y 9. Cada dígito está representado por una imagen en blanco y negro. \n",
    "\n",
    "<img style=\"float:center\" width=\"60%\" src=\"pics/MNIST_num.png\">\n",
    "\n",
    "El conjunto de datos **EMNIST** es un conjunto de dígitos y caracteres manuscritos derivados de la base de datos **NIST Special Database 19** y convertidos a un formato de imagen de 28x28 píxeles y a una estructura de conjunto de datos que coincide directamente con el conjunto de datos MNIST.\n",
    "\n",
    "<img style=\"float:center\" width=\"60%\" src=\"pics/EMNIST.png\">\n",
    "\n",
    "\n",
    "La base de datos **NIST Special Database 19** contiene todo el corpus de materiales de formación del NIST para el reconocimiento de documentos y caracteres impresos a mano. Dispone de información recopilada de impresos a mano de unos 3.600 escritores, lo que proporciona unas 810.000 imágenes con clasificaciones comprobadas a mano.\n",
    "\n",
    "Referencia: *Cohen, G., Afshar, S., Tapson, J., & van Schaik, A. (2017). EMNIST: an extension of MNIST to handwritten letters. Retrieved from http://arxiv.org/abs/1702.05373*\n",
    "\n",
    "Se trata de imagenes sencillas, con poca variabilidad entre ellas, por lo que es un problema que podemos abordar empleando un perceptrón simple.\n",
    "\n",
    "Cada imagen en MNIST está perfectamente centrada y el dataset se halla idóneamente balanceado. En el mundo real los datos no se comportan tan bien. Así mismo, los ejemplos que representan cada clase presentan, por definición, poca variabilidad (después de todo, no hay demasiadas formas de escribir un 1). \n",
    "\n",
    "<div class=\"alert alert-info\"> <b>IMPORTANTE</b><br> Se utilizará el perceptron implementado en <b>Introducción a Redes Neuronales</b> y será necesario tener presente lo tratado en <b>Fundamentos de Procesamiento de Imagen</b>.</div>\n",
    "\n",
    "Todos los datos de **EMNIST** se encuentran en formato `IDX`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### El formato IDX\n",
    "El formato de archivo IDX es un formato sencillo para vectores y matrices multidimensionales de diversos tipos numéricos. El formato básico es\n",
    "\n",
    "        magic number\n",
    "        size in dimension 0\n",
    "        size in dimension 1\n",
    "        size in dimension 2\n",
    "        .....\n",
    "        size in dimension N\n",
    "        data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En los datos de los que disponemos, tendremos un archivo de imágenes y un archivo de etiquetas. Ambos archivos se encuentran \"sincronizados\" de forma que la primera etiqueta del archivo de etiquetas se corresponde con la primera imagen del archivo de imágenes y así con todas. Cada uno de los archivos vendrá dado por el siguiente esquema:\n",
    "\n",
    "**ARCHIVO DE CONJUNTO DE ETIQUETAS (labels-idx1-ubyte):**\n",
    "\n",
    "    [offset] [type]          [value]          [description]\n",
    "    0000     32 bit integer  0x00000801(2049) magic number (MSB first)\n",
    "    0004     32 bit integer  60000            number of items\n",
    "    0008     unsigned byte   ??               label\n",
    "    0009     unsigned byte   ??               label\n",
    "    ........\n",
    "    xxxx     unsigned byte   ??               label\n",
    "Los valores de las etiquetas toman valores de 0 a 46.\n",
    "\n",
    "**ARCHIVO DE CONJUNTO DE IMAGENES (images-idx3-ubyte):**\n",
    "\n",
    "    [offset] [type]          [value]          [description]\n",
    "    0000     32 bit integer  0x00000803(2051) magic number\n",
    "    0004     32 bit integer  60000            number of images\n",
    "    0008     32 bit integer  28               number of rows\n",
    "    0012     32 bit integer  28               number of columns\n",
    "    0016     unsigned byte   ??               pixel\n",
    "    0017     unsigned byte   ??               pixel\n",
    "    ........\n",
    "    xxxx     unsigned byte   ??               pixel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objetivos:\n",
    "\n",
    "En esta práctica se emplearán las imágenes de *num-MNIST* y se cubrirán los siguientes puntos:\n",
    "\n",
    "1. Obtener un conjunto de datos $(X,y)$, donde:\n",
    "    - $X$ será un conjunto de *atributos* que describa una imagen. En este caso tomaremos los valores de los píxeles de una imagen.\n",
    "    - $y$ será la *clase*  \n",
    "    \n",
    "<br style=\"clear:both;\">\n",
    "\n",
    "2. Dividir el conjunto de datos (imágenes, en nuestro caso) en dos partes: \n",
    "    - (1) un conjunto de *entrenamiento* \n",
    "    - (2) un conjunto de *test*.  \n",
    "\n",
    "<br style=\"clear:both;\">\n",
    "\n",
    "3. Entrenar una *red neuronal* con la parte de los datos que forma el conjunto de *entrenamiento* y comprobar su funcionamiento con otra parte (conjunto de test), para la obtención de la tasa de acierto en el perceptrón simple.  \n",
    "    - Empleando el perceptrón propio.\n",
    "    - Empleando la red neuronal de **Sklearn**  \n",
    "\n",
    "<br style=\"clear:both;\">\n",
    "\n",
    "4. Manejar diferentes métricas y herramientas para testear un clasificador.\n",
    "    - Matriz de confusión\n",
    "    - Métricas:\n",
    "        - Exactitud\n",
    "        - Precisión\n",
    "        - Sensibilidad\n",
    "        \n",
    "<br style=\"clear:both;\">\n",
    "\n",
    "5. Implementar una red neuronal multicapa que permita clasificar todos los grupos de imágenes.\n",
    "\n",
    "<br style=\"clear:both;\">\n",
    "\n",
    "6. Introducir la validación cruzada como estrategia de valoración de un clasificador.\n",
    "\n",
    "<br style=\"clear:both;\">\n",
    "\n",
    "7. Añadir un nuevo conjunto de datos de test y obtener los resultados de rendimiento de las diferentes redes neuronales implementadas.\n",
    "\n",
    "----------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Datos\n",
    "\n",
    "## 1.1. Manejo de los archivos IDX\n",
    "\n",
    "- Descarga los archivos que se encuentran en la siguiente carpeta compartida MNIST: [Enlace Carpeta MNIST](https://universidaddeburgos-my.sharepoint.com/:f:/g/personal/dgarcia1_ubu_es/En7vGMQoS_tBo8fXA5F5dFoBC58TI9sJnWPBKqiUp3AUwQ?e=SmMkb3) \n",
    "\n",
    "- Descomprime correctamente cada uno de los archivos ```emnist-balanced-images-idx3-ubyte.gz``` y ```emnist-balanced-labels-idx1-ubyte.gz``` para obtener los datos de las imágenes y su correspondiente etiqueta.\n",
    "\n",
    "- Comprueba que puedes acceder a las imágenes empleando Python. \n",
    "    - El número de imágenes debe coincidir con el número de etiquetas\n",
    "    - Cada imagen tendrá asignada una etiqueta indexada en el mismo orden en el archivo ```labels```. Cada imagen tiene asignada una etiqueta que se corresponde con un indice (de 0 a 46), que se corresponderá a su vez con un caracter en formato ASCII (representado en la siguiente tabla entre comillas):\n",
    "<table style=\"font-size:large\">\n",
    "    <tr><td>0</td><td>\"0\"</td><td><img style=\"float:left\" width=\"100%\" src=\"pics/caracter_0.png\"></td><td>1</td><td>\"1\"</td><td><img style=\"float:left\" width=\"100%\" src=\"pics/caracter_1.png\"></td>\n",
    "    <td>2</td><td>\"2\"</td><td><img style=\"float:left\" width=\"100%\" src=\"pics/caracter_2.png\"></td><td>3</td><td>\"3\"</td><td><img style=\"float:left\" width=\"100%\" src=\"pics/caracter_3.png\"></td>\n",
    "    <td>4</td><td>\"4\"</td><td><img style=\"float:left\" width=\"100%\" src=\"pics/caracter_4.png\"></td><tr><td>5</td><td>\"5\"</td><td><img style=\"float:left\" width=\"100%\" src=\"pics/caracter_5.png\"></td>\n",
    "    <td>6</td><td>\"6\"</td><td><img style=\"float:left\" width=\"100%\" src=\"pics/caracter_6.png\"></td><td>7</td><td>\"7\"</td><td><img style=\"float:left\" width=\"100%\" src=\"pics/caracter_7.png\"></td>\n",
    "    <td>8</td><td>\"8\"</td><td><img style=\"float:left\" width=\"100%\" src=\"pics/caracter_8.png\"></td><td>9</td><td>\"9\"</td><td><img style=\"float:left\" width=\"100%\" src=\"pics/caracter_9.png\"></td></tr>\n",
    "    <tr><td>10</td><td>\"A\"</td><td><img style=\"float:left\" width=\"100%\" src=\"pics/caracter_10.png\"></td><td>11</td><td>\"B\"</td><td><img style=\"float:left\" width=\"100%\" src=\"pics/caracter_11.png\"></td>\n",
    "    <td>12</td><td>\"C\"</td><td><img style=\"float:left\" width=\"100%\" src=\"pics/caracter_12.png\"></td><td>3</td><td>\"D\"</td><td><img style=\"float:left\" width=\"100%\" src=\"pics/caracter_13.png\"></td>\n",
    "    <td>14</td><td>\"E\"</td><td><img style=\"float:left\" width=\"100%\" src=\"pics/caracter_14.png\"></td><tr><td>15</td><td>\"F\"</td><td><img style=\"float:left\" width=\"100%\" src=\"pics/caracter_15.png\"></td>\n",
    "    <td>16</td><td>\"G\"</td><td><img style=\"float:left\" width=\"100%\" src=\"pics/caracter_16.png\"></td><td>17</td><td>\"H\"</td><td><img style=\"float:left\" width=\"100%\" src=\"pics/caracter_17.png\"></td>\n",
    "    <td>18</td><td>\"I\"</td><td><img style=\"float:left\" width=\"100%\" src=\"pics/caracter_18.png\"></td><td>19</td><td>\"J\"</td><td><img style=\"float:left\" width=\"100%\" src=\"pics/caracter_19.png\"></td></tr>\n",
    "    <tr><td>20</td><td>\"K\"</td><td><img style=\"float:left\" width=\"100%\" src=\"pics/caracter_20.png\"></td><td>21</td><td>\"L\"</td><td><img style=\"float:left\" width=\"100%\" src=\"pics/caracter_21.png\"></td>\n",
    "    <td>22</td><td>\"M\"</td><td><img style=\"float:left\" width=\"100%\" src=\"pics/caracter_22.png\"></td><td>23</td><td>\"N\"</td><td><img style=\"float:left\" width=\"100%\" src=\"pics/caracter_23.png\"></td>\n",
    "    <td>24</td><td>\"O\"</td><td><img style=\"float:left\" width=\"100%\" src=\"pics/caracter_24.png\"></td><tr><td>25</td><td>\"P\"</td><td><img style=\"float:left\" width=\"100%\" src=\"pics/caracter_25.png\"></td>\n",
    "    <td>26</td><td>\"Q\"</td><td><img style=\"float:left\" width=\"100%\" src=\"pics/caracter_26.png\"></td><td>27</td><td>\"R\"</td><td><img style=\"float:left\" width=\"100%\" src=\"pics/caracter_27.png\"></td>\n",
    "    <td>28</td><td>\"S\"</td><td><img style=\"float:left\" width=\"100%\" src=\"pics/caracter_28.png\"></td><td>29</td><td>\"T\"</td><td><img style=\"float:left\" width=\"100%\" src=\"pics/caracter_29.png\"></td></tr>\n",
    "    <tr><td>30</td><td>\"U\"</td><td><img style=\"float:left\" width=\"100%\" src=\"pics/caracter_30.png\"></td><td>31</td><td>\"V\"</td><td><img style=\"float:left\" width=\"100%\" src=\"pics/caracter_31.png\"></td>\n",
    "    <td>32</td><td>\"W\"</td><td><img style=\"float:left\" width=\"100%\" src=\"pics/caracter_32.png\"></td><td>33</td><td>\"X\"</td><td><img style=\"float:left\" width=\"100%\" src=\"pics/caracter_33.png\"></td>\n",
    "    <td>34</td><td>\"Y\"</td><td><img style=\"float:left\" width=\"100%\" src=\"pics/caracter_34.png\"></td><tr><td>35</td><td>\"Z\"</td><td><img style=\"float:left\" width=\"100%\" src=\"pics/caracter_35.png\"></td>\n",
    "    <td>36</td><td>\"a\"</td><td><img style=\"float:left\" width=\"100%\" src=\"pics/caracter_36.png\"></td><td>37</td><td>\"b\"</td><td><img style=\"float:left\" width=\"100%\" src=\"pics/caracter_37.png\"></td>\n",
    "    <td>38</td><td>\"d\"</td><td><img style=\"float:left\" width=\"100%\" src=\"pics/caracter_38.png\"></td><td>39</td><td>\"e\"</td><td><img style=\"float:left\" width=\"100%\" src=\"pics/caracter_39.png\"></td></tr>\n",
    "    <tr><td>40</td><td>\"f\"</td><td><img style=\"float:left\" width=\"100%\" src=\"pics/caracter_40.png\"></td><td>41</td><td>\"g\"</td><td><img style=\"float:left\" width=\"100%\" src=\"pics/caracter_41.png\"></td>\n",
    "    <td>42</td><td>\"h\"</td><td><img style=\"float:left\" width=\"100%\" src=\"pics/caracter_42.png\"></td><td>43</td><td>\"n\"</td><td><img style=\"float:left\" width=\"100%\" src=\"pics/caracter_43.png\"></td>\n",
    "    <td>44</td><td>\"q\"</td><td><img style=\"float:left\" width=\"100%\" src=\"pics/caracter_44.png\"></td><tr><td>45</td><td>\"r\"</td><td><img style=\"float:left\" width=\"100%\" src=\"pics/caracter_45.png\"></td>\n",
    "    <td>46</td><td>\"t\"</td><td><img style=\"float:left\" width=\"100%\" src=\"pics/caracter_46.png\"></td></tr>\n",
    "</table>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La función `carga_data_MNIST` que permite cargar los datos de ambos archivos IDX:\n",
    "\n",
    "Funciones empleadas:\n",
    "- ```join```del módulo ```path```de ```os```.\n",
    "- ```open```del módulo ```gzip```.\n",
    "\n",
    "Obtenemos una lista de imágenes (que proviene del archivo de imágenes) y una lista de indices (proveniente del archivo de 'labels'):"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-20T08:28:32.813782Z",
     "start_time": "2024-11-20T08:28:32.805415Z"
    }
   },
   "source": [
    "def carga_data_MNIST(input_path,file_images, file_labels ):\n",
    "    \"\"\" Permite cargar los datos almacenados en formato IDX\n",
    "    Parámetros\n",
    "    ----------\n",
    "        input_path: Carpeta en la que se encuentran los archivos\n",
    "        file_images: nombre del archivo de imágenes\n",
    "        file_labels: nombre del archivo de etiquetas\n",
    "    \n",
    "    Devolución\n",
    "    --------\n",
    "        images -- array 3D con los datos de cada imagen\n",
    "        labels -- array 1D con el numero de clase de cada de las imágenes\n",
    "    \"\"\"     \n",
    "    import gzip\n",
    "\n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    from os.path  import join\n",
    "\n",
    "    images_path = join(input_path, file_images)\n",
    "    labels_path = join(input_path, file_labels)\n",
    "\n",
    "    ## Comenzamos con el archivo que contiene las imágenes:\n",
    "    print(\"***********************************\")\n",
    "    #Instanciamos el manejador de archivo mediante la función open \n",
    "    images_byte = gzip.open(images_path,'r')\n",
    "\n",
    "    #NÚMERO MAGICO\n",
    "    head=images_byte.read(4)\n",
    "    magic = int.from_bytes (head, \"big\")\n",
    "    print(\"Numero mágico para el archivo de imágenes:\")\n",
    "    print(magic)\n",
    "\n",
    "    #NUMERO DE IMAGENES\n",
    "    head=images_byte.read(4)\n",
    "    number_images = int.from_bytes (head, \"big\")\n",
    "    print(\"Numero de imágenes:\")\n",
    "    print(number_images)\n",
    "\n",
    "    #NUMERO DE FILAS DE LA IMAGEN\n",
    "    head=images_byte.read(4)\n",
    "    rows = int.from_bytes (head, \"big\")\n",
    "    print(\"Numero de filas (imágenes):\")\n",
    "    print(rows)\n",
    "\n",
    "    #NUMERO DE COLUMNAS DE LA IMAGEN\n",
    "    head=images_byte.read(4)\n",
    "    columns = int.from_bytes (head, \"big\")\n",
    "    print(\"Numero de columnas (imágenes):\")\n",
    "    print(columns)\n",
    "\n",
    "    #CARGA DE DATOS\n",
    "    buf = images_byte.read(rows * columns * number_images)\n",
    "    data = np.frombuffer(buf, dtype=np.uint8).astype(np.float32)\n",
    "    array = data.reshape(number_images, rows, columns)\n",
    "    images=array.swapaxes(1, 2)\n",
    "    \n",
    "    \n",
    "    ## A partir de aquí procesamos el archivo que contiene las etiquetas:\n",
    "    print(\"***********************************\")\n",
    "    labels_byte = gzip.open(labels_path,'r')\n",
    "\n",
    "    #NÚMERO MAGICO\n",
    "    head=labels_byte.read(4)\n",
    "    magic = int.from_bytes (head, \"big\")\n",
    "    print(\"Numero mágico para el archivo de etiquetas:\")\n",
    "    print(magic)\n",
    "\n",
    "    #NUMERO DE ETIQUETAS\n",
    "    head=labels_byte.read(4)\n",
    "    number_labels = int.from_bytes (head, \"big\")\n",
    "    print(\"Numero de etiquetas:\")\n",
    "    print(number_labels)\n",
    "\n",
    "    #CARGA DE ETIQUETAS\n",
    "    buf = labels_byte.read(number_labels)\n",
    "    labels = np.frombuffer(buf, dtype=np.uint8)\n",
    "    print(\"***********************************\")\n",
    "    \n",
    "    return images, labels"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Según los archivos proporcionados, se va a trabajar con `112800` imágenes y por tanto con `112800` etiquetas. El tamaño de cada una de las imágenes es de 28x28 píxeles.\n",
    "\n",
    "<div class=\"alert alert-warning\"> <b>IMPORTANTE</b><br> Antes de continuar, comprueba que los datos indicados coinciden con los obtenidos de los archivos IDX proporcionados.</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-20T08:28:58.010251Z",
     "start_time": "2024-11-20T08:28:56.882846Z"
    }
   },
   "source": [
    "input_path='Data'\n",
    "file_images= 'emnist-balanced-images-idx3-ubyte.gz'\n",
    "file_labels = 'emnist-balanced-labels-idx1-ubyte.gz'\n",
    "\n",
    "[images,labels]=carga_data_MNIST(input_path,file_images,file_labels)\n",
    "print(images.shape)\n",
    "print(labels.shape)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********************************\n",
      "Numero mágico para el archivo de imágenes:\n",
      "2051\n",
      "Numero de imágenes:\n",
      "112800\n",
      "Numero de filas (imágenes):\n",
      "28\n",
      "Numero de columnas (imágenes):\n",
      "28\n",
      "***********************************\n",
      "Numero mágico para el archivo de etiquetas:\n",
      "2049\n",
      "Numero de etiquetas:\n",
      "112800\n",
      "***********************************\n",
      "(112800, 28, 28)\n",
      "(112800,)\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `TAREA 1`\n",
    "\n",
    "Hasta el momento tenemos los valores de etiqueta obtenidos del archivo `labels`, pero este valor no nos proporciona información directa sobre el caracter que representa ese indice. Para ello tenemos a nuestra disposición un archivo que nos permite realizar esa 'traducción'. Se trata del archivo `claves_ASCII.txt` que se encuentra en la carpeta `MNIST_balanced`. \n",
    "\n",
    "Para poder trabajar en adelante con el caracter representado y no con el índice, se **solicita crear una función `crea_diccionario` con la que se obtenga un diccionario en el cual la clave será el indice (del 0 al 46) y el valor será el caracter ASCII que representa ('A', 'B', '0', '1'...)**. La función tendrá como parámetro de entrada un archivo de texto que será procesado convenientemente.\n",
    "\n",
    "De esta forma, la ejecución de la siguiente celda:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-20T08:57:09.922852Z",
     "start_time": "2024-11-20T08:57:09.918453Z"
    }
   },
   "source": [
    "from Tarea_1 import crea_diccionario\n",
    "archivo_claves= \"Data\\\\claves_ASCII.txt\"\n",
    "caracteres=crea_diccionario(archivo_claves)\n",
    "print(caracteres)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: '0', 1: '1', 2: '2', 3: '3', 4: '4', 5: '5', 6: '6', 7: '7', 8: '8', 9: '9', 10: 'A', 11: 'B', 12: 'C', 13: 'D', 14: 'E', 15: 'F', 16: 'G', 17: 'H', 18: 'I', 19: 'J', 20: 'K', 21: 'L', 22: 'M', 23: 'N', 24: 'O', 25: 'P', 26: 'Q', 27: 'R', 28: 'S', 29: 'T', 30: 'U', 31: 'V', 32: 'W', 33: 'X', 34: 'Y', 35: 'Z', 36: 'a', 37: 'b', 38: 'd', 39: 'e', 40: 'f', 41: 'g', 42: 'h', 43: 'n', 44: 'q', 45: 'r', 46: 't'}\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El resultado de la ejecución de la celda anterior, debería proporcionar una estructura de datos `caracteres` con el siguiente contenido:\n",
    "\n",
    "```\n",
    "{0: '0', 1: '1', 2: '2', 3: '3', 4: '4', 5: '5', 6: '6', 7: '7', 8: '8', 9: '9', 10: 'A', 11: 'B', 12: 'C', 13: 'D', 14: 'E', 15: 'F', 16: 'G', 17: 'H', 18: 'I', 19: 'J', 20: 'K', 21: 'L', 22: 'M', 23: 'N', 24: 'O', 25: 'P', 26: 'Q', 27: 'R', 28: 'S', 29: 'T', 30: 'U', 31: 'V', 32: 'W', 33: 'X', 34: 'Y', 35: 'Z', 36: 'a', 37: 'b', 38: 'd', 39: 'e', 40: 'f', 41: 'g', 42: 'h', 43: 'n', 44: 'q', 45: 'r', 46: 't'}\n",
    "\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 1.2. Procesado de las imágenes\n",
    "\n",
    "En las siguientes celdas vamos a ir viendo cual es el contenido de las estructuras de datos obtenidas de la lectura de los archivos `IDX`.\n",
    "\n",
    "Seleccionamos una de las imágenes y etiqueta que se encuentren pareadas al azar (deben coincidir en el índice):"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-20T09:23:36.928490Z",
     "start_time": "2024-11-20T09:23:36.917024Z"
    }
   },
   "source": [
    "img = images[83]\n",
    "eti = labels[83]\n",
    "print(eti)\n",
    "print(img)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "[[  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "    0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "    0.   0.   0.   1.   0.   0.   2.   2.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.   0.   8.  27.  14.  32.  26.\n",
      "   39.  82. 128. 159. 139. 129. 172. 126.  23.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.   2. 121. 190. 153. 203. 185.\n",
      "  217. 233. 250. 251. 250. 250. 252. 234. 154.   2.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.   4. 217. 254. 254. 254. 254.\n",
      "  254. 255. 254. 254. 254. 254. 255. 254. 217.   4.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.   4. 217. 254. 254. 254. 254.\n",
      "  253. 252. 245. 222. 236. 254. 255. 254. 217.   4.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.   2. 108. 127. 127. 127. 125.\n",
      "   94.  81.  36.  46. 179. 254. 254. 246. 158.   2.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.   0.   3.   4.   4.   4.   4.\n",
      "    3.   3.  79. 175. 246. 254. 254. 175.  36.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "    1.  35. 218. 251. 254. 254. 251.  83.   3.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   8.  34.\n",
      "  128. 221. 254. 254. 254. 244. 163.   7.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.   0.   3.  21.  38. 127. 204.\n",
      "  246. 254. 254. 255. 252. 132.  33.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.  32. 113. 172. 232. 249. 254. 254.\n",
      "  255. 255. 255. 255. 250.  52.   1.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0. 115. 241. 252. 254. 254. 255. 255.\n",
      "  254. 254. 254. 254. 254. 159.  22.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   4. 203. 254. 254. 254. 254. 245. 222.\n",
      "  205. 172. 174. 234. 254. 245. 114.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   4. 213. 252. 250. 233. 204. 115.  51.\n",
      "   33.  21.  25. 132. 246. 250. 140.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.  33.  80.  50.  21.   4.   0.   0.\n",
      "    0.   0.   0.  39. 217. 254. 219.   8.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.   2.   0.   0.   0.   0.   0.\n",
      "    0.   0.   0.  39. 217. 254. 228.  16.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "    0.   0.  67. 175. 247. 254. 217.   4.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "    1.  33. 187. 250. 254. 254. 203.   4.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   1.  22.\n",
      "  128. 221. 254. 254. 254. 242. 115.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   4.   2.   0.   2.   9.  52. 159.\n",
      "  246. 254. 254. 254. 251. 131.  32.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   7.  46. 124.  78.  35.  82. 139. 220. 247.\n",
      "  254. 254. 254. 249. 207.  23.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0. 113. 242. 254. 248. 246. 252. 254. 254. 254.\n",
      "  254. 234. 140. 109.  22.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0. 127. 250. 254. 254. 254. 254. 255. 254. 253.\n",
      "  218. 126.   9.   4.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0. 125. 246. 254. 254. 252. 250. 245. 204. 126.\n",
      "   11.   2.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.  63. 138. 215. 217. 172. 129. 114.  34.   8.\n",
      "    0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   4.   4.   2.   0.   0.   0.   0.\n",
      "    0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "    0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]]\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.1 Muestra una imagen\n",
    "\n",
    "Empleando las funciones de **skimage** que vimos en anteriores sesiones, podemos cargar y procesar las imágenes:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-20T09:04:18.069846Z",
     "start_time": "2024-11-20T09:04:17.912468Z"
    }
   },
   "source": [
    "from skimage.io import imshow, imread\n",
    "import matplotlib.pyplot as plt\n",
    "fig, ax = plt.subplots(figsize=(5, 5))\n",
    "ax.imshow(img,cmap='gray')\n",
    "ax.set_title(eti)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 500x500 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 11
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.2 Muestra varias imágenes\n",
    "\n",
    "Mediante la función `show_images` podemos mostrar varias imágenes y su correspondiente caracter:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-20T09:04:34.094596Z",
     "start_time": "2024-11-20T09:04:34.084453Z"
    }
   },
   "source": [
    "def show_images(images, labels, caracteres, columnas, filas):\n",
    "    \"\"\" Permite mostrar la primeras n imagenes ( n = columnas x filas)\n",
    "    Parámetros\n",
    "    ----------\n",
    "        images -- array 3D con los datos de cada imagen\n",
    "        labels -- array 1D con el numero de clase de cada de las imágenes\n",
    "        caracteres -- diccionario que proprociona el caracter que se corresponde a cada una de las imágenes\n",
    "        columnas: numero de columnas a mostrar\n",
    "        filas: numero de filas a mostrar\n",
    "    \"\"\"    \n",
    "    fig, ax = plt.subplots(ncols=columnas,nrows=filas,figsize=(10, 10))\n",
    "    axes=ax.ravel()\n",
    "    index = 0   \n",
    "     \n",
    "    for x in zip(images, labels):        \n",
    "        image = x[0]        \n",
    "        label = caracteres[x[1]]\n",
    "         \n",
    "        axes[index].imshow(image,cmap='gray')\n",
    "        axes[index].set_title(label)\n",
    "        axes[index].axis(\"off\")\n",
    " \n",
    "        plt.title(label);        \n",
    "        index += 1\n",
    "        if index>=(columnas*filas):\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "            return"
   ],
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-20T09:05:57.015949Z",
     "start_time": "2024-11-20T09:05:56.637048Z"
    }
   },
   "cell_type": "code",
   "source": "show_images(images,labels,caracteres,2,2)",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x1000 with 4 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 16
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si está todo correcto, la ejecución de:\n",
    "\n",
    "```python\n",
    "show_images(images,labels,caracteres,3,3)\n",
    "```\n",
    "\n",
    "debería proporcionar una imagen similar a esta:\n",
    "\n",
    "\n",
    "<img style=\"float:center\" width=\"60%\" src=\"pics/imagenes_labels.png\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.3 Características de las imágenes:\n",
    "\n",
    "Empleando propiedades específicas podemos obtener el tamaño de cada una de las imágenes:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-20T09:06:03.083406Z",
     "start_time": "2024-11-20T09:06:03.072936Z"
    }
   },
   "source": [
    "'''\n",
    "Obtener el tamaño de la imagen\n",
    "'''\n",
    "print(img.shape)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28, 28)\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-20T09:06:07.917194Z",
     "start_time": "2024-11-20T09:06:07.907519Z"
    }
   },
   "source": [
    "print(img.size) # alto x ancho (el número total de pixels)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "784\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.4 Modificando el formato de las imágenes:\n",
    "\n",
    "Para poder trabajar con los datos de las imágenes en las redes neuronales a implementar, tendremos que pasar de datos en dos dimensiones a una única dimensión:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-20T09:06:24.212464Z",
     "start_time": "2024-11-20T09:06:24.201983Z"
    }
   },
   "source": [
    "'''\n",
    "[[p00,p01],\n",
    " [p10,p11]]  => [p00,p01,p10,p11]\n",
    "\n",
    "'''\n",
    "# Se pasa a una sola fila y se convierte en lista (la imagen se \"vectoriza\")\n",
    "lista_pixels = img.reshape(img.size).tolist()\n",
    "\n",
    "# Muestro los primeros\n",
    "print(lista_pixels[:10])"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Además, para optimizar y facilitar el coste computacional de los procesos, vamos a reducir el tamaño de las imágenes, pasando a tener imágenes de 16x16:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-20T09:07:02.849992Z",
     "start_time": "2024-11-20T09:06:58.334288Z"
    }
   },
   "source": [
    "'''\n",
    "Redimensionar una imagen a 16 x 16\n",
    "'''\n",
    "\n",
    "from skimage.transform import resize\n",
    "import warnings\n",
    "\n",
    "'''\n",
    "El Método resize muestra un \"warning\", \n",
    "El Método filterwarnings permite ignorar el \"warning\" y que no se muestre en pantalla.\n",
    "''' \n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "fig, ax = plt.subplots(ncols=2,figsize=(10, 10))\n",
    "axes=ax.ravel()\n",
    "\n",
    "axes[0].imshow(img,cmap='gray')\n",
    "axes[0].set_title(\"Original (28x28)\")\n",
    "axes[0].axis(\"off\")\n",
    "\n",
    "\n",
    "img_mini =  resize(img, (16, 16))\n",
    "axes[1].imshow(img_mini,cmap='gray')\n",
    "axes[1].set_title(\"Resize (16x16)\")\n",
    "axes[1].axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x1000 with 2 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 20
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3. Obtención del conjunto de datos\n",
    "\n",
    "Para entrenar una red neuronal (o cualquier otro clasificador), se necesita un conjunto de datos.\n",
    "\n",
    "El conjunto de datos estará formado por $X$ e $y$. \n",
    "\n",
    "- $X$ será un array 2D con tantas filas como imágenes y tantas columnas como atributos se usen para describir cada imagen. En nuestro caso, los atributos serán simplemente los valores de los píxeles.\n",
    "- $y$ será un array de una sola dimensión, con tantos elementos como imágenes. Sus valores serán los nombres de las clases de cada imagen.\n",
    "\n",
    "***Ejemplo inventado***.\n",
    "Los valores de los atributos van entre 0 y 1 con formato float. Es 0 si el color del pixel es negro, y 1, si es blanco.\n",
    "<table>\n",
    "<tr style=\"border-top: 1px solid\"><th>X<sub>1</sub></th><th>X<sub>2</sub></th><th>...</th><th>X<sub>n</sub></th><th>y</th></tr>\n",
    "    <tr style=\"border-top: 1px solid\"><td>0.1</td><td>0.3</td><td>...</td><td>0.8</td><td>'a'</td></tr>\n",
    "    <tr style=\"border-top: 1px solid\"><td>0.2</td><td>0.2</td><td>...</td><td>0.3</td><td>'A'</td></tr>\n",
    "    <tr style=\"border-top: 1px solid\"><td>0.9</td><td>0.2</td><td>...</td><td>0.3</td><td>'b'</td></tr>\n",
    "    <tr style=\"border-top: 1px solid\"><td>0.9</td><td>0.5</td><td>...</td><td>0.3</td><td>'Z'</td></tr>\n",
    "    <tr style=\"border-top: 1px solid\"><td>0.8</td><td>0.7</td><td>...</td><td>0.8</td><td>'3'</td></tr>\n",
    "    <tr style=\"border-top: 1px solid\"><td>0.1</td><td>0.4</td><td>...</td><td>0.6</td><td>'8'</td></tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `TAREA 2`\n",
    "**Implementar una función *get_dataset()* que devuelva $X$ e $y$.** \n",
    "- HINT: para incluir todos los datos en un único vector se puede emplear *reshape*."
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-20T10:05:30.323464Z",
     "start_time": "2024-11-20T10:05:04.460897Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from Tarea_2 import getdataset\n",
    "Ximage, yimage=getdataset(images,labels, caracteres, 16)\n",
    "print(Ximage.shape,yimage.shape)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(112800, 256) (112800,)\n"
     ]
    }
   ],
   "execution_count": 47
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez cargados todos los archivos correctamente, ejecución de las siguientes líneas de código:\n",
    "```python\n",
    "Ximage, yimage=getdataset(images,labels, caracteres, 16)\n",
    "print(Ximage.shape,yimage.shape)\n",
    "```\n",
    "deberían mostrar por pantalla:\n",
    "\n",
    "```\n",
    "(112800, 256) (112800,)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Construcción y evaluación de un *clasificador de formas*. \n",
    "\n",
    "\n",
    "Tal y como ya hemos visto, en **Python** tenemos una librería de minería de datos llamada **Scikit-learn** o **Sklearn**. En el entrenamiento del perceptrón, trabajamos con esta librería puesto que nos permite entrenar muchos tipos de clasificadores, entre ellos, una **red neuronal**.\n",
    "\n",
    "Para esta práctica, por el momento, solamente tenemos un conjunto de imágenes, por lo que unicamente disponemos un conjunto de datos. \n",
    "\n",
    "## 2.1 Creación de los conjuntos de datos\n",
    "\n",
    "Para comprobar el funcionamiento de nuestro clasificador, necesitamos un conjunto de datos de entrenamiento que nos permita configurar el percetrón. Es decir, tenemos que descomponer el conjunto de datos en dos subconjuntos: \n",
    "* entrenamiento\n",
    "\n",
    "* test.\n",
    "\n",
    "Para este trabajo, vamos a implementar una *partición* de **70/30**, para *entrenamiento/test*.\n",
    "\n",
    "El método ```train_test_split``` del módulo ```sklearn.model_selection``` permite dividir un conjunto de datos en dos partes, una para entrenar el clasificador, y otra para evaluar su funcionamiento (test).\n",
    "\n",
    "<div class=\"alert alert-info\"> <b>from</b> sklearn.model_selection <b>import</b> train_test_split<br>\n",
    "    <b>help </b>(train_test_split)<br></div>\n",
    "\n",
    "**Importante:** El uso de la propiedad de *estratificación* (```stratify```) como flag en el método ```train_test_split``` permite que haya la misma proporción de clases en entrenamiento que en test."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para ello emplearemos una llamada al método `train_test_split` de la siguiente manera:\n",
    "\n",
    "```Python\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "'''\n",
    "El par X_train, y_train son los atributos y clases del conjunto de entrenamiento (70% de los ejemplos)\n",
    "El par X_test, y_test son los atributos y clases del conjunto de test (30% de los ejemplos)\n",
    "\n",
    "stratify (estratificar) significa que se quiere que haya la misma proporcion de cada una de las clases\n",
    "tanto en entrenamiento como en test, es decir, no es una partición completamente aleatoria.\n",
    "'''\n",
    "X_train, X_test, y_train, y_test = train_test_split(Ximage, yimage, stratify=yimage, train_size = 0.7 )\n",
    "\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En nuestro ejemplo, tenemos 47 clases diferentes, cada una de ellas con 2400 imágenes, por lo tanto:\n",
    "- 112800 imágenes en total\n",
    "    - **78960** serán de entrenamiento **(70%)**\n",
    "    - **33840** serán de test **(30%)**\n",
    "        \n",
    "- Dado que están balanceadas por clases, para cada caracter (\"0\", \"1\",...\"A\", \"B\",...) tendremos:\n",
    "    - 2400 imagenes por clase\n",
    "        - 1680 imágenes de entrenamiento\n",
    "        - 720 imágenes de test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La ejecución del siguiente código:\n",
    "\n",
    "```python\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)\n",
    "print(X_train.shape)\n",
    "print(X_train[0:20])\n",
    "print(y_train[0:20])\n",
    "```\n",
    "\n",
    "nos debe proporcionar una salida similar a esta:\n",
    " ```\n",
    " (78960,)\n",
    "(33840,)\n",
    "(78960, 256)\n",
    "[[0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
    "  0.00000000e+00 0.00000000e+00]\n",
    " [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
    "  0.00000000e+00 0.00000000e+00]\n",
    " [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
    "  0.00000000e+00 0.00000000e+00]\n",
    " ...\n",
    " [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
    "  0.00000000e+00 0.00000000e+00]\n",
    " [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 4.80951887e-04\n",
    "  7.97951483e-09 0.00000000e+00]\n",
    " [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 4.16548263e-12\n",
    "  0.00000000e+00 0.00000000e+00]]\n",
    "['S' 'Z' 'G' 'S' 'G' '8' 'W' 'X' 'a' 'H' 'F' 'b' 'b' 'B' 'W' 'K' 'V' 'W'\n",
    " 'E' 'C']\n",
    " ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Clasificación con perceptrón simple\n",
    "\n",
    "El perceptron simple que tenemos implementado de la sesión anterior, unicamente es capaz de clasificar dos clases a la vez.\n",
    "\n",
    "Además, tal cual hemos realizado nuestra implementación, las clases serán binarias, no nombres.\n",
    "\n",
    "Veamos un ejemplo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Uso de la máscara booleana \n",
    "- Seleccionar solo los datos que cumplan un criterio\n",
    "- convertir un array de algún tipo en un array de 0s y 1s, con 1s donde se cumple el criterio\n",
    "\n",
    "'''\n",
    "import numpy as np \n",
    "\n",
    "a = np.array([1,2,3,4,5,6])\n",
    "mascara = a < 4\n",
    "\n",
    "print(mascara)\n",
    "print(a[mascara])\n",
    "\n",
    "# astype cambia al tipo que se quiera\n",
    "print(mascara.astype(int)) # los True se convierten en 1s los False en 0s\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el caso de las imágenes con las que estamos trabajando, el planteamiento es similar, solo que tendremos que seleccionar un par de clases. Por ejemplo:\n",
    "\n",
    "```Python \n",
    "'''\n",
    "Seleccionamos sólo los casos en los que la clase sea \"A\" o \"3\" (por ejemplo)\n",
    "\n",
    "X_2C de todos los ejemplos de X solo se seleccionan aquellos donde la clase es \"A\" o \"3\"\n",
    "y_2C de todos los ejemplos de y solo se seleccionan aquellos donde la clase es \"A\" o \"3\"\n",
    "'''\n",
    "X_2C = Ximage[((yimage == 'A') | (yimage == '3'))]\n",
    "y_2C = yimage[((yimage == 'A') | (yimage == '3'))\n",
    "\n",
    "# Tenemos solo dos clases, pero las etiquetas siguen siendo cadenas de texto\n",
    "print(X_2C.shape)\n",
    "print(X_2C)\n",
    "print(y_2C.shape)\n",
    "print(y_2C)\n",
    "\n",
    "```\n",
    "\n",
    "debemos obtener:\n",
    "\n",
    "```\n",
    "(4800, 256)\n",
    "[[5.57877143e-14 6.62299868e-08 1.92427193e-03 ... 0.00000000e+00\n",
    "  0.00000000e+00 0.00000000e+00]\n",
    " [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
    "  0.00000000e+00 0.00000000e+00]\n",
    " [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
    "  0.00000000e+00 0.00000000e+00]\n",
    " ...\n",
    " [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
    "  0.00000000e+00 0.00000000e+00]\n",
    " [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
    "  0.00000000e+00 0.00000000e+00]\n",
    " [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
    "  0.00000000e+00 0.00000000e+00]]\n",
    "(4800,)\n",
    "['3' '3' '3' ... 'A' 'A' 'A']\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tenemos que convertir el array de caracteres a un array de '0s' y '1s'. \n",
    "\n",
    "<div class=\"alert alert-info\"> <b>Recuerda:</b><br> \"True\" se evalúa como \"1\".</div>\n",
    "\n",
    "```Python\n",
    "y_2C_num = (y_2C == 'A').astype(int)\n",
    "y_2C_num\n",
    "\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con esto ya podemos crear los conjuntos de datos de entrenamiento y test compatibles con nuestro perceptrón:\n",
    "\n",
    "```Python\n",
    "from sklearn.model_selection import train_test_split\n",
    "X2C_train, X2C_test, y2C_train, y2C_test = train_test_split(X_2C, y_2C_num, stratify=y_2C_num, train_size = 0.7 )\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `TAREA 3`\n",
    "\n",
    "Incluye las funciones `entrena_perceptron`, `predice` y `evalua` en el archivo donde vayas a organizar las funciones implementadas y comprueba su funcionamiento con los datos de entrenamiento y test "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "from modules import entrena_perceptron,evalua #Tendras que ajustar esta importación de acuerdo a tu archivo de funciones.\n",
    "z = 0.0     # umbral\n",
    "eta = 0.1   # learning rate\n",
    "t = 50      # número de iteraciones\n",
    "\n",
    "weights, errors = entrena_perceptron(X2C_train, y2C_train, z, eta, t,funcion_escalon)\n",
    "y_pred_2C_own=predice(weights,X2C_test,z,funcion_escalon)\n",
    "porcentaje_acierto_perceptron_own=evalua(y2C_test, y_pred_2C_own)\n",
    "print(porcentaje_acierto_perceptron_own)\n",
    "\n",
    "```\n",
    "\n",
    "Debemos obtener un valor alrededor de 0.99"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De la misma forma podemos emplear las funciones que nos permiten crear un perceptrón en `sklearn`:\n",
    "\n",
    "```Python\n",
    "from sklearn.linear_model import Perceptron\n",
    "from modules import evalua #Tendras que ajustar esta importación de acuerdo a tu archivo de funciones.\n",
    "\n",
    "clf = Perceptron(random_state=None, eta0= 0.1, shuffle=True, fit_intercept=True)\n",
    "clf.fit(X2C_train, y2C_train)\n",
    "y_pred_2C_sk = clf.predict(X2C_test)\n",
    "\n",
    "porcentaje_acierto_perceptron_sk=evalua(y2C_test, y_pred_2C_sk)\n",
    "print(porcentaje_acierto_perceptron_sk)\n",
    "```\n",
    "\n",
    "Obtendremos un valor similar al obtenido por el perceptrón propio."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Punto 4. Elementos para la valoración de la predicción.\n",
    "\n",
    "### Matriz de confusión\n",
    "\n",
    "En este punto vamos a introducir una forma de presentar los resultados obtenidos en la clasificación de clases a partir de la matriz de confusión.\n",
    "\n",
    "<div class=\"alert alert-info\"> <b>from</b> sklearn <b>import</b> metrics<br>\n",
    "    <b>help </b>(metrics.confusion_matrix)<br>\n",
    "    <b>help </b>(metrics.ConfusionMatrixDisplay)<br></div>\n",
    "    \n",
    "\n",
    "    \n",
    "Los valores de la diagonal principal se corresponden con los valores estimados de forma correcta por el modelo. El resto de datos representan los casos en los que el modelo *«se ha equivocado»*.\n",
    "\n",
    "<img style=\"float:center\" width=\"60%\" src=\"pics/matrix_confusion_n2.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Supongamos que estamos intentando clasificar ```A``` y tenemos un conjunto de datos con ```A```y ```3```.\n",
    "\n",
    "En la matriz de confusión, los valores de la diagonal principal se corresponden con los valores estimados de forma correcta por el modelo (los que clasifica como ```A``` y ```3```), tanto los verdaderos positivos *True Positive(TP)* (en este caso los que clasifica como ```A``` y que son realmente ```A```) como los verdaderos negativos *True Negative(TN)* (los que clasifica como ```3``` y por tanto no son ```A```).\n",
    "\n",
    "<img style=\"float:center\" width=\"60%\" src=\"pics/matrizconfusionMetricas.png\">\n",
    "\n",
    "La otra diagonal, representa los casos en los que el modelo «se ha equivocado»:\n",
    "- Falsos negativos (FN). Si estamos evaluando la clase ```A```, casos que siendo ```A``` lo considera ```3```.\n",
    "- Falsos positivos (FP). Si estamos evaluando la clase ```A```, casos que siendo ```3``` lo considera ```A```. \n",
    "\n",
    "\n",
    "**IMPORTANTE**: Para cada una de las clases tendremos unos valores u otros dependiendo de cual estemos evaluando, simplemente cambiando el orden de la matriz de confusión.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "import numpy as np \n",
    "\n",
    "labels=np.unique(y2C_test)\n",
    "\n",
    "conf_mat = metrics.confusion_matrix(y2C_test, y_pred_2C_own,labels=labels)\n",
    "cm_display = metrics.ConfusionMatrixDisplay(confusion_matrix = conf_mat, display_labels = [\"3\" , \"A\"])\n",
    "fig, ax = plt.subplots(figsize=(10,10))\n",
    "cm_display.plot(ax=ax)\n",
    "plt.title(\"Matriz de confusión Perceptron propio (A-3)\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "import numpy as np \n",
    "\n",
    "labels=np.unique(y2C_test)\n",
    "\n",
    "conf_mat = metrics.confusion_matrix(y2C_test, y_pred_2C_sk,labels=labels)\n",
    "cm_display = metrics.ConfusionMatrixDisplay(confusion_matrix = conf_mat, display_labels = [\"3\" , \"A\"])\n",
    "fig, ax = plt.subplots(figsize=(10,10))\n",
    "cm_display.plot(ax=ax)\n",
    "plt.title(\"Matriz de confusión Perceptron simple de Sklearn (A-3)\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Métricas: \n",
    "\n",
    "A partir de la matriz de confusión se pueden derivar varias métricas. Estas son las tres más importantes:\n",
    "\n",
    "- **Exactitud (accuracy)**: Porcentaje de predicciones correctas. Se corresponde con el valor obtenido de nuestra función `evalua`.\n",
    "- **Precisión (precision)**: Porcentaje de predicciones positivas correctas.\n",
    "- **Sensibilidad (recall)** representa la tasa de verdaderos positivos. Es la proporción entre los casos positivos bien clasificados por el modelo, respecto al total de positivos. \n",
    "\n",
    "<div class=\"alert alert-info\"> <b>from</b> sklearn <b>import</b> metrics<br>\n",
    "    <b>    help </b>(metrics.accuracy_score)<br>\n",
    "    <b>    help </b>(metrics.precision_score)<br>\n",
    "    <b>    help </b>(metrics.recall_score)<br>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "accuracy=metrics.accuracy_score(y2C_test, y_pred_2C_own)\n",
    "print(\"Exactitud: \" + str(accuracy))\n",
    "\n",
    "precision =metrics.precision_score(y2C_test, y_pred_2C_own,average=None) \n",
    "#Incluimos el parametro average=None para que calcule la métrica de precisión en las dos clases\n",
    "print(\"Precisión: \" + str(precision))\n",
    "\n",
    "sensibilidad =metrics.recall_score(y2C_test, y_pred_2C_own,average=None)\n",
    "print(\"Sensibilidad: \" + str(sensibilidad))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "accuracy=metrics.accuracy_score(y2C_test, y_pred_2C_sk)\n",
    "print(\"Exactitud: \" + str(accuracy))\n",
    "\n",
    "precision =metrics.precision_score(y2C_test, y_pred_2C_sk,average=None) \n",
    "#Incluimos el parametro average=None para que calcule la métrica de precisión en las dos clases\n",
    "print(\"Precisión: \" + str(precision))\n",
    "\n",
    "sensibilidad =metrics.recall_score(y2C_test, y_pred_2C_sk,average=None)\n",
    "print(\"Sensibilidad: \" + str(sensibilidad))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `TAREA 4`\n",
    "\n",
    "- ¿Que ocurre con la matriz de confusión y las métricas que se obtienen de la función `evalua` cuando ejecutamos de forma repetida el entrenamiento y predicción de cada perceptrón, por ejemplo 10 veces?\n",
    "\n",
    "```Python\n",
    "from modules import entrena_perceptron,evalua #Tendras que ajustar esta importación de acuerdo a tu archivo de funciones.\n",
    "from sklearn.linear_model import Perceptron\n",
    "\n",
    "z = 0.0     # umbral\n",
    "eta = 0.1   # learning rate\n",
    "t = 50      # número de iteraciones\n",
    "\n",
    "for i in range(10):\n",
    "    weights, errors = entrena_perceptron(X2C_train, y2C_train, z, eta, t,funcion_escalon)\n",
    "    y_pred_2C_own=predice(weights,X2C_test,z,funcion_escalon)\n",
    "    clf = Perceptron(random_state=None, eta0= 0.1, shuffle=True, fit_intercept=True)\n",
    "    clf.fit(X2C_train, y2C_train)\n",
    "    y_pred_2C_sk = clf.predict(X2C_test)\n",
    "\n",
    "    print(\"----------Round \" + str(i) + \"------------------\")\n",
    "    accuracy=metrics.accuracy_score(y2C_test, y_pred_2C_own)\n",
    "    print(\"Exactitud_own: \" + str(accuracy))\n",
    "    \n",
    "    precision =metrics.precision_score(y2C_test, y_pred_2C_own,average=None) \n",
    "    #Incluimos el parametro average=None para que calcule la métrica de precisión en las dos clases\n",
    "    print(\"Precisión_own: \" + str(precision))\n",
    "    \n",
    "    sensibilidad =metrics.recall_score(y2C_test, y_pred_2C_own,average=None)\n",
    "    print(\"Sensibilidad_own: \" + str(sensibilidad))\n",
    "\n",
    "    accuracy=metrics.accuracy_score(y2C_test, y_pred_2C_sk)\n",
    "    print(\"Exactitud_sk: \" + str(accuracy))\n",
    "\n",
    "    precision =metrics.precision_score(y2C_test, y_pred_2C_sk,average=None) \n",
    "    print(\"Precisión_sk: \" + str(precision))\n",
    "\n",
    "    sensibilidad =metrics.recall_score(y2C_test, y_pred_2C_sk,average=None)\n",
    "    print(\"Sensibilidad_sk: \" + str(sensibilidad))\n",
    "    \n",
    "    \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `TAREA 5`\n",
    "\n",
    "- Se solicita analizar la matriz de confusión y sus correspondientes métricas para todos los diferentes pares de imágenes empleando el perceptrón de sklearn. Por ejemplo:\n",
    "    * 0 - 1\n",
    "    * 0 - 2\n",
    "    * 0 - 3\n",
    "    * ...\n",
    "    * A - 0\n",
    "    * A - 1\n",
    "    * ...\n",
    "\n",
    "**Importante**: Implementa las funciones necesarias para que se automatice el proceso.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "## Punto 5.  Perceptrón Multicapa (MLP)\n",
    "\n",
    "En **Sklearn**, todos los clasificadores tienen el mismo funcionamiento. Se crea el clasificador (si no indicamos ningún argumento) con todos los parámetros por defecto. Luego:\n",
    "- el método **fit** entrena el clasificador\n",
    "- el método **predict** recibe uno o varios ejemplos y nos devuelve las clases que estima el clasificador.\n",
    "\n",
    "Dado que en nuestro planteamiento tenemos *N* clases, no podemos resolver el problema con un único perceptrón. Por tanto, necesitamos un perceptrón multicapa:\n",
    "<div class=\"alert alert-info\"> <b>from</b> sklearn.neural_network <b>import</b> MLPClassifier<br>\n",
    "    <b>help </b>(MLPClassifier)<br></div>\n",
    "    \n",
    "**Atributos de MLPClassifier:**\n",
    "\n",
    "    n_layers_int: Número de capas.\n",
    "    \n",
    "    n_outputs_int: Número de salidas.\n",
    "        \n",
    "    out_activation_str: Nombre de la función de activación.\n",
    "\n",
    "\n",
    "***Links interesantes:***\n",
    "- https://interactivechaos.com/es/manual/tutorial-de-deep-learning/la-clase-mlpclassifier-de-scikit-learn\n",
    "- https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html\n",
    "- https://es.wikipedia.org/wiki/Funci%C3%B3n_SoftMax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Entrena un clasificador (Perceptrón multicapa) con el conjunto de entrenamiento\n",
    "'''\n",
    "\n",
    "# puede tardar unos segundos\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "classifier = MLPClassifier()\n",
    "\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "print(\"Numero de capas: \" + str(classifier.n_layers_))\n",
    "print(\"Numero de salidas: \" + str(classifier.n_outputs_))\n",
    "print(\"Función de activación: \" + str(classifier.out_activation_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = classifier.predict(X_test)\n",
    "y_pred[:10] # muestra las 10 primeras\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "import numpy as np \n",
    "\n",
    "labels=np.unique(y_test)\n",
    "\n",
    "conf_mat = metrics.confusion_matrix(y_test, y_pred,labels=labels)\n",
    "cm_display = metrics.ConfusionMatrixDisplay(confusion_matrix = conf_mat, display_labels = labels)\n",
    "fig, ax = plt.subplots(figsize=(10,10))\n",
    "cm_display.plot(ax=ax)\n",
    "plt.title(\"Matriz de confusión Perceptron Multicapa de Sklearn\")\n",
    "plt.xticks(rotation='vertical')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `TAREA 6`\n",
    "- Ejecuta las celdas anteriores para obtener la matriz de confusión para todo el conjunto de imágenes, empleando el perceptrón múlticapa e incluye los resultados de las métricas. \n",
    "- En la carpeta MNIST se encuentra los archivos `emnist-balanced-test-images-idx3-ubyte.gz` y `emnist-balanced-test-labels-idx1-ubyte.gz`. Emplea todo lo visto para el perceptrón multicapa en la práctica para trabajar con estos datos de forma que estos sean los datos de test y **todos** los empleados anteriormente, que se encuentran en `emnist-balanced-images-idx3-ubyte.gz` y `emnist-balanced-labels-idx1-ubyte.gz`, sirvan como datos de entrenamiento.\n",
    "    - ¿Que resultados de metricas se obtienen?\n",
    "    - ¿Hay diferencias con los obtenidos anteriormente (matriz de confusión y métricas)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Punto 6. Validación cruzada\n",
    "\n",
    "En los procesos de entrenamiento de un clasificador, es conveniente realizar una evaluación de los clasificadores y nos interese modificar de forma sistemática las dos muestras (entrenamiento y test) para evaluar de una manera mas específica el comportamiento del clasificador.\n",
    "\n",
    "Disponemos de métricas que hemos aplicado a muestras obtenidas de la división de la muestra en dos subconjuntos mutuamente excluyentes (mediante **train_test_split**), aunque esta estrategia puede provocar desviaciones en la estimación del error.\n",
    "\n",
    "Para solventar este problema, se emplea la **validación cruzada** (cross-validation, leave-one-out). En este método se parte de un conjunto de datos de *m* muestras y se procede a entrenar el clasificador con *m-1* muestras dejando una fuera (de ahí su denominación). Posteriormente, evaluamos las respuestas del clasificador para la muestra que se quedó fuera. Este proceso se repite *m* veces, dejando fuera una muestra diferente en cada caso.\n",
    "\n",
    "\n",
    "<div class=\"alert alert-info\"> <b>from</b> sklearn.model_selection <b>import</b> cross_val_predict<br>\n",
    "    <b>help </b>(cross_val_predict)<br></div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validación cruzada para perceptrón simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "import numpy as np\n",
    "X_2C = Ximage[((yimage == 'A') | (yimage == '3'))]\n",
    "y_2C = yimage[((yimage == 'A') | (yimage == '3'))]\n",
    "y_2C_pred = cross_val_predict(Perceptron(random_state=None, eta0= 0.1, shuffle=False, fit_intercept=False), X_2C, y_2C, cv=3)\n",
    "labels=np.unique(y_2C)\n",
    "conf_mat = confusion_matrix(y_2C, y_2C_pred,labels=labels)\n",
    "cm_display = metrics.ConfusionMatrixDisplay(confusion_matrix = conf_mat, display_labels = labels)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,10))\n",
    "cm_display.plot(ax=ax)\n",
    "plt.title(\"Matriz de confusión. Validación cruzada. Perceptron simple (A-3)\")\n",
    "plt.show()\n",
    "\n",
    "porcentaje_acierto=evalua(y_2C, y_2C_pred)\n",
    "print(\"Porcentaje de acierto: \" + str(porcentaje_acierto))\n",
    "accuracy=metrics.accuracy_score(y_2C, y_2C_pred)\n",
    "print(\"Exactitud: \" + str(accuracy))\n",
    "precision =metrics.precision_score(y_2C,y_2C_pred,average=None)\n",
    "print(\"Precisión: \" + str(precision))\n",
    "sensibilidad =metrics.recall_score(y_2C, y_2C_pred,average=None)\n",
    "print(\"Sensibilidad: \" + str(sensibilidad))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validación cruzada para perceptrón multicapa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "import numpy as np\n",
    "y_pred = cross_val_predict(MLPClassifier(), Ximage, yimage, cv=3)\n",
    "labels=np.unique(yimage)\n",
    "conf_mat = confusion_matrix(yimage, y_pred,labels=labels)\n",
    "cm_display = metrics.ConfusionMatrixDisplay(confusion_matrix = conf_mat, display_labels = labels)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(30,30))\n",
    "cm_display.plot(ax=ax)\n",
    "plt.xticks(rotation='vertical')\n",
    "plt.title(\"Matriz de confusión MLP - Datos EMNIST\")\n",
    "plt.show()\n",
    "\n",
    "accuracy=metrics.accuracy_score(yimage, y_pred)\n",
    "print(\"Exactitud: \" + str(accuracy))\n",
    "\n",
    "precision =metrics.precision_score(yimage, y_pred,average=None) \n",
    "print(\"Precisión: \" + str(precision))\n",
    "\n",
    "sensibilidad =metrics.recall_score(yimage, y_pred,average=None)\n",
    "print(\"Sensibilidad: \" + str(sensibilidad))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `TAREA 7`\n",
    "\n",
    "- Desde un punto de vista del usuario que emplea este clasificador de imágenes, ¿qué conclusiones puedes obtener a partir de los resultados obtenidos para la clasificación de imágenes en la validación cruzada, tanto con el perceptrón simple como multicapa?\n",
    " - ¿Cómo varían los resultados cuando realizamos el análisis con todos los datos disponibles (incluir en un unico dataset los datos originales y datos de test de la tarea 6)?\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
